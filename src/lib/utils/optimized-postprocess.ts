/** * ä¼˜åŒ–åProcessæ¨¡å— * æä¾›é«˜æ€§èƒ½segmentsProcessï¼Œæ”¯æŒæ™ºèƒ½åˆ†classã€å¹¶å‘æ§åˆ¶å’Œæ‰¹Process*/

import Groq from "groq-sdk";

export interface Segment {
  text: string;
  start: number;
  end: number;
}

export interface ProcessedSegment {
  originalText: string;
  normalizedText: string;
  translation?: string;
  annotations?: string[];
  furigana?: string;
  start: number;
  end: number;
}

export interface PostProcessOptions {
  targetLanguage?: string;
  enableAnnotations?: boolean;
  enableFurigana?: boolean;
  maxConcurrent?: number;
  batchSize?: number;
}

const DEFAULT_OPTIONS: Required<PostProcessOptions> = {
  targetLanguage: "en",
  enableAnnotations: true,
  enableFurigana: true,
  maxConcurrent: 8,
  batchSize: 20,
};

const GROQ_CHAT_MODEL = "openai/gpt-oss-20b";

class OptimizedPostProcessor {
  private groqClient: Groq;

  constructor() {
    this.groqClient = new Groq({ apiKey: process.env.GROQ_API_KEY });
  }

  /** * ä¸»è¦Processå…¥å£ - æ™ºèƒ½åˆ†classå’Œå¹¶è¡ŒProcess*/
  async processSegments(
    segments: Segment[],
    sourceLanguage: string,
    options: PostProcessOptions = {},
  ): Promise<ProcessedSegment[]> {
    const finalOptions = { ...DEFAULT_OPTIONS, ...options };
    const startTime = Date.now();

    console.log(`ğŸš€ å¼€å§‹ä¼˜åŒ–åå¤„ç†: ${segments.length} segments`);

    // æ™ºèƒ½æ–‡æœ¬åˆ†class
    const categorizedSegments = this.categorizeSegments(segments);
    console.log(
      `æ–‡æœ¬åˆ†ç±»: æçŸ­ ${categorizedSegments.ultraShort.length}, ` +
        `çŸ­ ${categorizedSegments.short.length}, ` +
        `ä¸­ ${categorizedSegments.medium.length}, ` +
        `é•¿ ${categorizedSegments.long.length}`,
    );

    // å¹¶è¡ŒProcessæ‰€æœ‰classåˆ«
    const processingPromises = [
      this.processUltraShortTexts(categorizedSegments.ultraShort, sourceLanguage, finalOptions),
      this.processShortTexts(categorizedSegments.short, sourceLanguage, finalOptions),
      this.processMediumTexts(categorizedSegments.medium, sourceLanguage, finalOptions),
      this.processLongTexts(categorizedSegments.long, sourceLanguage, finalOptions),
    ];

    const results = await Promise.allSettled(processingPromises);
    const allProcessed: ProcessedSegment[] = [];

    results.forEach((result, index) => {
      if (result.status === "fulfilled") {
        allProcessed.push(...result.value);
        const categoryNames = ["æçŸ­æ–‡æœ¬", "çŸ­æ–‡æœ¬", "ä¸­ç­‰æ–‡æœ¬", "é•¿æ–‡æœ¬"];
        console.log(`âœ… ${categoryNames[index]}å¤„ç†å®Œæˆ: ${result.value.length} ä¸ª`);
      } else {
        console.error(`âŒ å¤„ç†ç±»åˆ« ${index} å¤±è´¥:`, result.reason);
      }
    });

    // ä¿æŒåŸå§‹é¡ºåº
    const orderedResults = this.maintainOriginalOrder(segments, allProcessed);

    const endTime = Date.now();
    const processingTime = endTime - startTime;
    const avgTimePerSegment = processingTime / segments.length;

    console.log(
      `ğŸ‰ ä¼˜åŒ–åå¤„ç†å®Œæˆ! æ€»è€—æ—¶: ${processingTime}ms, ` +
        `å¹³å‡: ${avgTimePerSegment.toFixed(2)}ms/segment`,
    );

    return orderedResults;
  }

  /** * æ™ºèƒ½æ–‡æœ¬åˆ†class*/
  private categorizeSegments(segments: Segment[]) {
    const ULTRA_SHORT_THRESHOLD = 15;
    const SHORT_THRESHOLD = 50;
    const MEDIUM_THRESHOLD = 120;

    return {
      ultraShort: segments.filter((seg) => seg.text.length <= ULTRA_SHORT_THRESHOLD),
      short: segments.filter(
        (seg) => seg.text.length > ULTRA_SHORT_THRESHOLD && seg.text.length <= SHORT_THRESHOLD,
      ),
      medium: segments.filter(
        (seg) => seg.text.length > SHORT_THRESHOLD && seg.text.length <= MEDIUM_THRESHOLD,
      ),
      long: segments.filter((seg) => seg.text.length > MEDIUM_THRESHOLD),
    };
  }

  /** * ProcessæçŸ­æ–‡æœ¬ - è¶…å¤§batch*/
  private async processUltraShortTexts(
    segments: Segment[],
    sourceLanguage: string,
    options: Required<PostProcessOptions>,
  ): Promise<ProcessedSegment[]> {
    if (segments.length === 0) return [];

    const BATCH_SIZE = 50; // æå¤§æ‰¹æ¬¡
    const results: ProcessedSegment[] = [];

    for (let i = 0; i < segments.length; i += BATCH_SIZE) {
      const batch = segments.slice(i, i + BATCH_SIZE);
      const batchResults = await this.processBatchOptimized(batch, sourceLanguage, options);
      results.push(...batchResults);
    }

    return results;
  }

  /** * ProcessçŸ­æ–‡æœ¬ - å¹¶è¡Œbatch*/
  private async processShortTexts(
    segments: Segment[],
    sourceLanguage: string,
    options: Required<PostProcessOptions>,
  ): Promise<ProcessedSegment[]> {
    if (segments.length === 0) return [];

    const BATCH_SIZE = 25;
    const CONCURRENT_BATCHES = Math.min(4, Math.ceil(segments.length / BATCH_SIZE));
    const results: ProcessedSegment[] = [];

    // åˆ›å»ºæ‰¹æ¬¡
    const batches: Segment[][] = [];
    for (let i = 0; i < segments.length; i += BATCH_SIZE) {
      batches.push(segments.slice(i, i + BATCH_SIZE));
    }

    // å¹¶è¡ŒProcessæ‰¹æ¬¡
    for (let i = 0; i < batches.length; i += CONCURRENT_BATCHES) {
      const currentBatches = batches.slice(i, i + CONCURRENT_BATCHES);
      const batchPromises = currentBatches.map((batch) =>
        this.processBatchOptimized(batch, sourceLanguage, options),
      );

      const batchResults = await Promise.allSettled(batchPromises);
      batchResults.forEach((result) => {
        if (result.status === "fulfilled") {
          results.push(...result.value);
        }
      });

      // å¾®å°delay
      if (i + CONCURRENT_BATCHES < batches.length) {
        await new Promise((resolve) => setTimeout(resolve, 20));
      }
    }

    return results;
  }

  /** * Processinç­‰é•¿åº¦æ–‡æœ¬ - é€‚inå¹¶å‘*/
  private async processMediumTexts(
    segments: Segment[],
    sourceLanguage: string,
    options: Required<PostProcessOptions>,
  ): Promise<ProcessedSegment[]> {
    if (segments.length === 0) return [];

    const CONCURRENT = Math.min(6, segments.length);
    const chunks = this.chunkArray(segments, Math.ceil(segments.length / CONCURRENT));

    const chunkPromises = chunks.map((chunk) =>
      this.processChunkSequentially(chunk, sourceLanguage, options),
    );

    const chunkResults = await Promise.allSettled(chunkPromises);
    const results: ProcessedSegment[] = [];

    chunkResults.forEach((result) => {
      if (result.status === "fulfilled") {
        results.push(...result.value);
      }
    });

    return results;
  }

  /** * Processé•¿æ–‡æœ¬ - ä¿å®ˆå¹¶å‘*/
  private async processLongTexts(
    segments: Segment[],
    sourceLanguage: string,
    options: Required<PostProcessOptions>,
  ): Promise<ProcessedSegment[]> {
    if (segments.length === 0) return [];

    const CONCURRENT = Math.min(3, segments.length);
    const chunks = this.chunkArray(segments, Math.ceil(segments.length / CONCURRENT));

    const chunkPromises = chunks.map(
      (chunk) => this.processChunkSequentially(chunk, sourceLanguage, options, 100), // é•¿æ–‡æœ¬å¢åŠ delay
    );

    const chunkResults = await Promise.allSettled(chunkPromises);
    const results: ProcessedSegment[] = [];

    chunkResults.forEach((result) => {
      if (result.status === "fulfilled") {
        results.push(...result.value);
      }
    });

    return results;
  }

  /** * ä¼˜åŒ–batchProcess*/
  private async processBatchOptimized(
    segments: Segment[],
    sourceLanguage: string,
    options: Required<PostProcessOptions>,
  ): Promise<ProcessedSegment[]> {
    if (segments.length === 1) {
      return [await this.processSingleSegment(segments[0], sourceLanguage, options)];
    }

    const combinedText = segments.map((seg, index) => `[SEGMENT_${index}] ${seg.text}`).join("\n");

    const prompt = this.buildBatchPrompt(combinedText, sourceLanguage, options);

    try {
      const response = await this.groqClient.chat.completions.create({
        model: GROQ_CHAT_MODEL,
        temperature: 0.2, // é™ä½æ¸©åº¦æé«˜ä¸€è‡´æ€§
        messages: [
          {
            role: "system",
            content:
              "You are a professional language teacher. Process multiple text segments efficiently. Respond with valid JSON only.",
          },
          { role: "user", content: prompt },
        ],
      });

      const responseText = response.choices[0]?.message?.content || "";
      const parsedResponse = this.parseBatchResponse(responseText, segments.length);

      return segments.map((segment, index) => {
        const processed = parsedResponse.segments[index];
        return {
          originalText: segment.text,
          normalizedText: processed?.normalizedText || segment.text,
          translation: processed?.translation || "",
          annotations: processed?.annotations || [],
          furigana: processed?.furigana || "",
          start: segment.start,
          end: segment.end,
        };
      });
    } catch (error) {
      console.error("æ‰¹é‡å¤„ç†å¤±è´¥ï¼Œä½¿ç”¨fallback:", error);
      return this.createFallbackResults(segments);
    }
  }

  /** * é¡ºåºProcesså—*/
  private async processChunkSequentially(
    segments: Segment[],
    sourceLanguage: string,
    options: Required<PostProcessOptions>,
    delay: number = 50,
  ): Promise<ProcessedSegment[]> {
    const results: ProcessedSegment[] = [];

    for (let i = 0; i < segments.length; i++) {
      const segment = segments[i];
      try {
        const processed = await this.processSingleSegment(segment, sourceLanguage, options);
        results.push(processed);
      } catch (error) {
        console.error(`å¤„ç†segment ${i} å¤±è´¥:`, error);
        results.push(this.createFallbackResult(segment));
      }

      // Adddelayä»¥é¿å…APIé™æµ
      if (i < segments.length - 1 && delay > 0) {
        await new Promise((resolve) => setTimeout(resolve, delay));
      }
    }

    return results;
  }

  /** * Processå•ä¸ªsegment*/
  private async processSingleSegment(
    segment: Segment,
    sourceLanguage: string,
    options: Required<PostProcessOptions>,
  ): Promise<ProcessedSegment> {
    const prompt = this.buildSinglePrompt(segment.text, sourceLanguage, options);

    const response = await this.groqClient.chat.completions.create({
      model: GROQ_CHAT_MODEL,
      temperature: 0.3,
      messages: [
        {
          role: "system",
          content:
            "You are a professional language teacher. Provide accurate, educational responses. Respond with valid JSON.",
        },
        { role: "user", content: prompt },
      ],
    });

    const responseText = response.choices[0]?.message?.content || "";
    const parsed = this.parseSingleResponse(responseText);

    return {
      originalText: segment.text,
      normalizedText: parsed.normalizedText || segment.text,
      translation: parsed.translation || "",
      annotations: parsed.annotations || [],
      furigana: parsed.furigana || "",
      start: segment.start,
      end: segment.end,
    };
  }

  /** * æ„å»ºbatchProcessæç¤º*/
  private buildBatchPrompt(
    combinedText: string,
    sourceLanguage: string,
    _options: Required<PostProcessOptions>,
  ): string {
    return `Process these ${sourceLanguage} text segments for language learning:

${combinedText}

Return JSON:
{
  "segments": [
    {
      "id": 0,
      "normalizedText": "clean text",
      "translation": "translation",
      "annotations": ["notes"],
      "furigana": "reading"
    }
  ]
}`;
  }

  /** * æ„å»ºå•ä¸ªsegmentæç¤º*/
  private buildSinglePrompt(
    text: string,
    sourceLanguage: string,
    options: Required<PostProcessOptions>,
  ): string {
    let prompt = `Process this ${sourceLanguage} text: "${text}"`;

    if (options.targetLanguage !== sourceLanguage) {
      prompt += `\nProvide translation to ${options.targetLanguage}`;
    }

    if (options.enableAnnotations) {
      prompt += `\nAdd grammatical/cultural annotations`;
    }

    if (options.enableFurigana && sourceLanguage === "ja") {
      prompt += `\nInclude furigana`;
    }

    prompt += `\n\nRespond with JSON: { "normalizedText": "...", "translation": "...", "annotations": [...], "furigana": "..." }`;

    return prompt;
  }

  /** * è§£æbatchresponse*/
  private parseBatchResponse(responseText: string, segmentCount: number) {
    try {
      let cleanedText = responseText.trim();
      if (cleanedText.startsWith("```json")) cleanedText = cleanedText.slice(7);
      if (cleanedText.startsWith("```")) cleanedText = cleanedText.slice(3);
      if (cleanedText.endsWith("```")) cleanedText = cleanedText.slice(0, -3);

      const jsonStart = cleanedText.indexOf("{");
      const jsonEnd = cleanedText.lastIndexOf("}");

      if (jsonStart !== -1 && jsonEnd !== -1 && jsonEnd > jsonStart) {
        cleanedText = cleanedText.substring(jsonStart, jsonEnd + 1);
      }

      const parsed = JSON.parse(cleanedText);
      return {
        segments: parsed.segments || Array(segmentCount).fill({}),
      };
    } catch (error) {
      console.error("è§£ææ‰¹é‡å“åº”å¤±è´¥:", error);
      return { segments: [] };
    }
  }

  /** * è§£æå•ä¸ªresponse*/
  private parseSingleResponse(responseText: string) {
    try {
      let cleanedText = responseText.trim();
      if (cleanedText.startsWith("```json")) cleanedText = cleanedText.slice(7);
      if (cleanedText.startsWith("```")) cleanedText = cleanedText.slice(3);
      if (cleanedText.endsWith("```")) cleanedText = cleanedText.slice(0, -3);

      const jsonStart = cleanedText.indexOf("{");
      const jsonEnd = cleanedText.lastIndexOf("}");

      if (jsonStart !== -1 && jsonEnd !== -1 && jsonEnd > jsonStart) {
        cleanedText = cleanedText.substring(jsonStart, jsonEnd + 1);
      }

      return JSON.parse(cleanedText);
    } catch (error) {
      console.error("è§£æå•ä¸ªå“åº”å¤±è´¥:", error);
      return {};
    }
  }

  /** * åˆ›å»ºfallbackç»“æœ*/
  private createFallbackResults(segments: Segment[]): ProcessedSegment[] {
    return segments.map((segment) => this.createFallbackResult(segment));
  }

  private createFallbackResult(segment: Segment): ProcessedSegment {
    return {
      originalText: segment.text,
      normalizedText: segment.text,
      translation: "",
      annotations: [],
      furigana: "",
      start: segment.start,
      end: segment.end,
    };
  }

  /** * ä¿æŒåŸå§‹é¡ºåº*/
  private maintainOriginalOrder(
    originalSegments: Segment[],
    processedResults: ProcessedSegment[],
  ): ProcessedSegment[] {
    return originalSegments.map((originalSegment) => {
      const matching = processedResults.find(
        (result) =>
          Math.abs(result.start - originalSegment.start) < 0.1 &&
          Math.abs(result.end - originalSegment.end) < 0.1,
      );

      return matching || this.createFallbackResult(originalSegment);
    });
  }

  /** * æ•°ç»„åˆ†å—*/
  private chunkArray<T>(array: T[], chunkSize: number): T[][] {
    const chunks: T[][] = [];
    for (let i = 0; i < array.length; i += chunkSize) {
      chunks.push(array.slice(i, i + chunkSize));
    }
    return chunks;
  }
}

// å¯¼å‡ºå•ä¾‹å®ä¾‹
export const optimizedPostProcessor = new OptimizedPostProcessor();

// ä¾¿æ·å‡½æ•°
export async function processSegmentsOptimized(
  segments: Segment[],
  sourceLanguage: string,
  options?: PostProcessOptions,
): Promise<ProcessedSegment[]> {
  return optimizedPostProcessor.processSegments(segments, sourceLanguage, options);
}
